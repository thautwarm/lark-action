# The file was automatically generated by Lark v0.11.3
__version__ = "0.11.3"

#
#
#   Lark Stand-alone Generator Tool
# ----------------------------------
# Generates a stand-alone LALR(1) parser with a standard lexer
#
# Git:    https://github.com/erezsh/lark
# Author: Erez Shinan (erezshin@gmail.com)
#
#
#    >>> LICENSE
#
#    This tool and its generated code use a separate license from Lark,
#    and are subject to the terms of the Mozilla Public License, v. 2.0.
#    If a copy of the MPL was not distributed with this
#    file, You can obtain one at https://mozilla.org/MPL/2.0/.
#
#    If you wish to purchase a commercial license for this tool and its
#    generated code, you may contact me via email or otherwise.
#
#    If MPL2 is incompatible with your free or open-source project,
#    contact me and we'll work it out.
#
#

from io import open


class LarkError(Exception):
    pass


class ConfigurationError(LarkError, ValueError):
    pass


def assert_config(value, options, msg="Got %r, expected one of %s"):
    if value not in options:
        raise ConfigurationError(msg % (value, options))


class GrammarError(LarkError):
    pass


class ParseError(LarkError):
    pass


class LexError(LarkError):
    pass


class UnexpectedInput(LarkError):
    # --
    pos_in_stream = None
    _terminals_by_name = None

    def get_context(self, text, span=40):
        # --
        assert self.pos_in_stream is not None, self
        pos = self.pos_in_stream
        start = max(pos - span, 0)
        end = pos + span
        if not isinstance(text, bytes):
            before = text[start:pos].rsplit("\n", 1)[-1]
            after = text[pos:end].split("\n", 1)[0]
            return before + after + "\n" + " " * len(before.expandtabs()) + "^\n"
        else:
            before = text[start:pos].rsplit(b"\n", 1)[-1]
            after = text[pos:end].split(b"\n", 1)[0]
            return (
                before + after + b"\n" + b" " * len(before.expandtabs()) + b"^\n"
            ).decode("ascii", "backslashreplace")

    def match_examples(
        self, parse_fn, examples, token_type_match_fallback=False, use_accepts=False
    ):
        # --
        assert self.state is not None, "Not supported for this exception"

        if isinstance(examples, dict):
            examples = examples.items()

        candidate = (None, False)
        for i, (label, example) in enumerate(examples):
            assert not isinstance(example, STRING_TYPE)

            for j, malformed in enumerate(example):
                try:
                    parse_fn(malformed)
                except UnexpectedInput as ut:
                    if ut.state == self.state:
                        if (
                            use_accepts
                            and hasattr(self, "accepts")
                            and ut.accepts != self.accepts
                        ):
                            logger.debug(
                                "Different accepts with same state[%d]: %s != %s at example [%s][%s]"
                                % (self.state, self.accepts, ut.accepts, i, j)
                            )
                            continue
                        try:
                            if ut.token == self.token:  ##

                                logger.debug("Exact Match at example [%s][%s]" % (i, j))
                                return label

                            if token_type_match_fallback:
                                ##

                                if (ut.token.type == self.token.type) and not candidate[
                                    -1
                                ]:
                                    logger.debug(
                                        "Token Type Fallback at example [%s][%s]"
                                        % (i, j)
                                    )
                                    candidate = label, True

                        except AttributeError:
                            pass
                        if candidate[0] is None:
                            logger.debug(
                                "Same State match at example [%s][%s]" % (i, j)
                            )
                            candidate = label, False

        return candidate[0]

    def _format_expected(self, expected):
        if self._terminals_by_name:
            d = self._terminals_by_name
            expected = [
                d[t_name].user_repr() if t_name in d else t_name for t_name in expected
            ]
        return "Expected one of: \n\t* %s\n" % "\n\t* ".join(expected)


class UnexpectedEOF(ParseError, UnexpectedInput):
    def __init__(self, expected, state=None, terminals_by_name=None):
        self.expected = expected
        self.state = state
        from .lexer import Token

        self.token = Token("<EOF>", "")  ##

        self.pos_in_stream = -1
        self.line = -1
        self.column = -1
        self._terminals_by_name = terminals_by_name

        super(UnexpectedEOF, self).__init__()

    def __str__(self):
        message = "Unexpected end-of-input. "
        message += self._format_expected(self.expected)
        return message


class UnexpectedCharacters(LexError, UnexpectedInput):
    def __init__(
        self,
        seq,
        lex_pos,
        line,
        column,
        allowed=None,
        considered_tokens=None,
        state=None,
        token_history=None,
        terminals_by_name=None,
        considered_rules=None,
    ):
        ##

        self.line = line
        self.column = column
        self.pos_in_stream = lex_pos
        self.state = state
        self._terminals_by_name = terminals_by_name

        self.allowed = allowed
        self.considered_tokens = considered_tokens
        self.considered_rules = considered_rules
        self.token_history = token_history

        if isinstance(seq, bytes):
            self.char = seq[lex_pos : lex_pos + 1].decode("ascii", "backslashreplace")
        else:
            self.char = seq[lex_pos]
        self._context = self.get_context(seq)

        super(UnexpectedCharacters, self).__init__()

    def __str__(self):
        message = (
            "No terminal matches '%s' in the current parser context, at line %d col %d"
            % (self.char, self.line, self.column)
        )
        message += "\n\n" + self._context
        if self.allowed:
            message += self._format_expected(self.allowed)
        if self.token_history:
            message += "\nPrevious tokens: %s\n" % ", ".join(
                repr(t) for t in self.token_history
            )
        return message


class UnexpectedToken(ParseError, UnexpectedInput):
    # --

    def __init__(
        self,
        token,
        expected,
        considered_rules=None,
        state=None,
        interactive_parser=None,
        terminals_by_name=None,
        token_history=None,
    ):
        ##

        self.line = getattr(token, "line", "?")
        self.column = getattr(token, "column", "?")
        self.pos_in_stream = getattr(token, "pos_in_stream", None)
        self.state = state

        self.token = token
        self.expected = expected  ##

        self._accepts = NO_VALUE
        self.considered_rules = considered_rules
        self.interactive_parser = interactive_parser
        self._terminals_by_name = terminals_by_name
        self.token_history = token_history

        super(UnexpectedToken, self).__init__()

    @property
    def accepts(self):
        if self._accepts is NO_VALUE:
            self._accepts = (
                self.interactive_parser and self.interactive_parser.accepts()
            )
        return self._accepts

    def __str__(self):
        message = "Unexpected token %r at line %s, column %s.\n%s" % (
            self.token,
            self.line,
            self.column,
            self._format_expected(self.accepts or self.expected),
        )
        if self.token_history:
            message += "Previous tokens: %r\n" % self.token_history

        return message

    @property
    def puppet(self):
        warn(
            "UnexpectedToken.puppet attribute has been renamed to interactive_parser",
            DeprecationWarning,
        )
        return self.interactive_parser


class VisitError(LarkError):
    # --

    def __init__(self, rule, obj, orig_exc):
        self.obj = obj
        self.orig_exc = orig_exc

        message = 'Error trying to process rule "%s":\n\n%s' % (rule, orig_exc)
        super(VisitError, self).__init__(message)


import sys, re
import logging
from io import open

logger = logging.getLogger("lark")
logger.addHandler(logging.StreamHandler())
##

##

logger.setLevel(logging.CRITICAL)

if sys.version_info[0] > 2:
    from abc import ABC, abstractmethod
else:
    from abc import ABCMeta, abstractmethod

    class ABC(object):  ##

        __slots__ = ()
        __metclass__ = ABCMeta


Py36 = sys.version_info[:2] >= (3, 6)

NO_VALUE = object()


def classify(seq, key=None, value=None):
    d = {}
    for item in seq:
        k = key(item) if (key is not None) else item
        v = value(item) if (value is not None) else item
        if k in d:
            d[k].append(v)
        else:
            d[k] = [v]
    return d


def _deserialize(data, namespace, memo):
    if isinstance(data, dict):
        if "__type__" in data:  ##

            class_ = namespace[data["__type__"]]
            return class_.deserialize(data, memo)
        elif "@" in data:
            return memo[data["@"]]
        return {
            key: _deserialize(value, namespace, memo) for key, value in data.items()
        }
    elif isinstance(data, list):
        return [_deserialize(value, namespace, memo) for value in data]
    return data


class Serialize(object):
    # --

    def memo_serialize(self, types_to_memoize):
        memo = SerializeMemoizer(types_to_memoize)
        return self.serialize(memo), memo.serialize()

    def serialize(self, memo=None):
        if memo and memo.in_types(self):
            return {"@": memo.memoized.get(self)}

        fields = getattr(self, "__serialize_fields__")
        res = {f: _serialize(getattr(self, f), memo) for f in fields}
        res["__type__"] = type(self).__name__
        postprocess = getattr(self, "_serialize", None)
        if postprocess:
            postprocess(res, memo)
        return res

    @classmethod
    def deserialize(cls, data, memo):
        namespace = getattr(cls, "__serialize_namespace__", {})
        namespace = {c.__name__: c for c in namespace}

        fields = getattr(cls, "__serialize_fields__")

        if "@" in data:
            return memo[data["@"]]

        inst = cls.__new__(cls)
        for f in fields:
            try:
                setattr(inst, f, _deserialize(data[f], namespace, memo))
            except KeyError as e:
                raise KeyError("Cannot find key for class", cls, e)
        postprocess = getattr(inst, "_deserialize", None)
        if postprocess:
            postprocess()
        return inst


class SerializeMemoizer(Serialize):
    # --

    __serialize_fields__ = ("memoized",)

    def __init__(self, types_to_memoize):
        self.types_to_memoize = tuple(types_to_memoize)
        self.memoized = Enumerator()

    def in_types(self, value):
        return isinstance(value, self.types_to_memoize)

    def serialize(self):
        return _serialize(self.memoized.reversed(), None)

    @classmethod
    def deserialize(cls, data, namespace, memo):
        return _deserialize(data, namespace, memo)


try:
    STRING_TYPE = basestring
except NameError:  ##

    STRING_TYPE = str


import types
from functools import wraps, partial
from contextlib import contextmanager

Str = type(u"")
try:
    classtype = types.ClassType  ##

except AttributeError:
    classtype = type  ##


def smart_decorator(f, create_decorator):
    if isinstance(f, types.FunctionType):
        return wraps(f)(create_decorator(f, True))

    elif isinstance(f, (classtype, type, types.BuiltinFunctionType)):
        return wraps(f)(create_decorator(f, False))

    elif isinstance(f, types.MethodType):
        return wraps(f)(create_decorator(f.__func__, True))

    elif isinstance(f, partial):
        ##

        return wraps(f.func)(
            create_decorator(lambda *args, **kw: f(*args[1:], **kw), True)
        )

    else:
        return create_decorator(f.__func__.__call__, True)


try:
    import regex
except ImportError:
    regex = None

import sre_parse
import sre_constants

categ_pattern = re.compile(r"\\p{[A-Za-z_]+}")


def get_regexp_width(expr):
    if regex:
        ##

        ##

        ##

        regexp_final = re.sub(categ_pattern, "A", expr)
    else:
        if re.search(categ_pattern, expr):
            raise ImportError(
                "`regex` module must be installed in order to use Unicode categories.",
                expr,
            )
        regexp_final = expr
    try:
        return [int(x) for x in sre_parse.parse(regexp_final).getwidth()]
    except sre_constants.error:
        raise ValueError(expr)


from collections import OrderedDict


class Meta:
    def __init__(self):
        self.empty = True


class Tree(object):
    # --
    def __init__(self, data, children, meta=None):
        self.data = data
        self.children = children
        self._meta = meta

    @property
    def meta(self):
        if self._meta is None:
            self._meta = Meta()
        return self._meta

    def __repr__(self):
        return "Tree(%r, %r)" % (self.data, self.children)

    def _pretty_label(self):
        return self.data

    def _pretty(self, level, indent_str):
        if len(self.children) == 1 and not isinstance(self.children[0], Tree):
            return [
                indent_str * level,
                self._pretty_label(),
                "\t",
                "%s" % (self.children[0],),
                "\n",
            ]

        l = [indent_str * level, self._pretty_label(), "\n"]
        for n in self.children:
            if isinstance(n, Tree):
                l += n._pretty(level + 1, indent_str)
            else:
                l += [indent_str * (level + 1), "%s" % (n,), "\n"]

        return l

    def pretty(self, indent_str="  "):
        # --
        return "".join(self._pretty(0, indent_str))

    def __eq__(self, other):
        try:
            return self.data == other.data and self.children == other.children
        except AttributeError:
            return False

    def __ne__(self, other):
        return not (self == other)

    def __hash__(self):
        return hash((self.data, tuple(self.children)))

    def iter_subtrees(self):
        # --
        queue = [self]
        subtrees = OrderedDict()
        for subtree in queue:
            subtrees[id(subtree)] = subtree
            queue += [
                c
                for c in reversed(subtree.children)
                if isinstance(c, Tree) and id(c) not in subtrees
            ]

        del queue
        return reversed(list(subtrees.values()))

    def find_pred(self, pred):
        # --
        return filter(pred, self.iter_subtrees())

    def find_data(self, data):
        # --
        return self.find_pred(lambda t: t.data == data)


from inspect import getmembers, getmro


class Discard(Exception):
    # --
    pass


##


class _Decoratable:
    # --

    @classmethod
    def _apply_decorator(cls, decorator, **kwargs):
        mro = getmro(cls)
        assert mro[0] is cls
        libmembers = {name for _cls in mro[1:] for name, _ in getmembers(_cls)}
        for name, value in getmembers(cls):

            ##

            if name.startswith("_") or (
                name in libmembers and name not in cls.__dict__
            ):
                continue
            if not callable(value):
                continue

            ##

            if hasattr(cls.__dict__[name], "vargs_applied") or hasattr(
                value, "vargs_applied"
            ):
                continue

            static = isinstance(cls.__dict__[name], (staticmethod, classmethod))
            setattr(cls, name, decorator(value, static=static, **kwargs))
        return cls

    def __class_getitem__(cls, _):
        return cls


class Transformer(_Decoratable):
    # --
    __visit_tokens__ = True  ##

    def __init__(self, visit_tokens=True):
        self.__visit_tokens__ = visit_tokens

    def _call_userfunc(self, tree, new_children=None):
        ##

        children = new_children if new_children is not None else tree.children
        try:
            f = getattr(self, tree.data)
        except AttributeError:
            return self.__default__(tree.data, children, tree.meta)
        else:
            try:
                wrapper = getattr(f, "visit_wrapper", None)
                if wrapper is not None:
                    return f.visit_wrapper(f, tree.data, children, tree.meta)
                else:
                    return f(children)
            except (GrammarError, Discard):
                raise
            except Exception as e:
                raise VisitError(tree.data, tree, e)

    def _call_userfunc_token(self, token):
        try:
            f = getattr(self, token.type)
        except AttributeError:
            return self.__default_token__(token)
        else:
            try:
                return f(token)
            except (GrammarError, Discard):
                raise
            except Exception as e:
                raise VisitError(token.type, token, e)

    def _transform_children(self, children):
        for c in children:
            try:
                if isinstance(c, Tree):
                    yield self._transform_tree(c)
                elif self.__visit_tokens__ and isinstance(c, Token):
                    yield self._call_userfunc_token(c)
                else:
                    yield c
            except Discard:
                pass

    def _transform_tree(self, tree):
        children = list(self._transform_children(tree.children))
        return self._call_userfunc(tree, children)

    def transform(self, tree):
        # --
        return self._transform_tree(tree)

    def __mul__(self, other):
        # --
        return TransformerChain(self, other)

    def __default__(self, data, children, meta):
        # --
        return Tree(data, children, meta)

    def __default_token__(self, token):
        # --
        return token


class InlineTransformer(Transformer):  ##
    def _call_userfunc(self, tree, new_children=None):
        ##

        children = new_children if new_children is not None else tree.children
        try:
            f = getattr(self, tree.data)
        except AttributeError:
            return self.__default__(tree.data, children, tree.meta)
        else:
            return f(*children)


class TransformerChain(object):
    def __init__(self, *transformers):
        self.transformers = transformers

    def transform(self, tree):
        for t in self.transformers:
            tree = t.transform(tree)
        return tree

    def __mul__(self, other):
        return TransformerChain(*self.transformers + (other,))


class Transformer_InPlace(Transformer):
    # --
    def _transform_tree(self, tree):  ##

        return self._call_userfunc(tree)

    def transform(self, tree):
        for subtree in tree.iter_subtrees():
            subtree.children = list(self._transform_children(subtree.children))

        return self._transform_tree(tree)


class Transformer_NonRecursive(Transformer):
    # --

    def transform(self, tree):
        ##

        rev_postfix = []
        q = [tree]
        while q:
            t = q.pop()
            rev_postfix.append(t)
            if isinstance(t, Tree):
                q += t.children

        ##

        stack = []
        for x in reversed(rev_postfix):
            if isinstance(x, Tree):
                size = len(x.children)
                if size:
                    args = stack[-size:]
                    del stack[-size:]
                else:
                    args = []
                stack.append(self._call_userfunc(x, args))
            elif self.__visit_tokens__ and isinstance(x, Token):
                stack.append(self._call_userfunc_token(x))
            else:
                stack.append(x)

        (t,) = stack  ##

        return t


class Transformer_InPlaceRecursive(Transformer):
    # --
    def _transform_tree(self, tree):
        tree.children = list(self._transform_children(tree.children))
        return self._call_userfunc(tree)


##


class VisitorBase:
    def _call_userfunc(self, tree):
        return getattr(self, tree.data, self.__default__)(tree)

    def __default__(self, tree):
        # --
        return tree

    def __class_getitem__(cls, _):
        return cls


class Visitor(VisitorBase):
    # --

    def visit(self, tree):
        # --
        for subtree in tree.iter_subtrees():
            self._call_userfunc(subtree)
        return tree

    def visit_topdown(self, tree):
        # --
        for subtree in tree.iter_subtrees_topdown():
            self._call_userfunc(subtree)
        return tree


class Visitor_Recursive(VisitorBase):
    # --

    def visit(self, tree):
        # --
        for child in tree.children:
            if isinstance(child, Tree):
                self.visit(child)

        self._call_userfunc(tree)
        return tree

    def visit_topdown(self, tree):
        # --
        self._call_userfunc(tree)

        for child in tree.children:
            if isinstance(child, Tree):
                self.visit_topdown(child)

        return tree


def visit_children_decor(func):
    # --
    @wraps(func)
    def inner(cls, tree):
        values = cls.visit_children(tree)
        return func(cls, values)

    return inner


class Interpreter(_Decoratable):
    # --

    def visit(self, tree):
        f = getattr(self, tree.data)
        wrapper = getattr(f, "visit_wrapper", None)
        if wrapper is not None:
            return f.visit_wrapper(f, tree.data, tree.children, tree.meta)
        else:
            return f(tree)

    def visit_children(self, tree):
        return [
            self.visit(child) if isinstance(child, Tree) else child
            for child in tree.children
        ]

    def __getattr__(self, name):
        return self.__default__

    def __default__(self, tree):
        return self.visit_children(tree)


##


def _apply_decorator(obj, decorator, **kwargs):
    try:
        _apply = obj._apply_decorator
    except AttributeError:
        return decorator(obj, **kwargs)
    else:
        return _apply(decorator, **kwargs)


def _inline_args__func(func):
    @wraps(func)
    def create_decorator(_f, with_self):
        if with_self:

            def f(self, children):
                return _f(self, *children)

        else:

            def f(self, children):
                return _f(*children)

        return f

    return smart_decorator(func, create_decorator)


def inline_args(obj):  ##

    return _apply_decorator(obj, _inline_args__func)


def _visitor_args_func_dec(func, visit_wrapper=None, static=False):
    def create_decorator(_f, with_self):
        if with_self:

            def f(self, *args, **kwargs):
                return _f(self, *args, **kwargs)

        else:

            def f(self, *args, **kwargs):
                return _f(*args, **kwargs)

        return f

    if static:
        f = wraps(func)(create_decorator(func, False))
    else:
        f = smart_decorator(func, create_decorator)
    f.vargs_applied = True
    f.visit_wrapper = visit_wrapper
    return f


def _vargs_inline(f, _data, children, _meta):
    return f(*children)


def _vargs_meta_inline(f, _data, children, meta):
    return f(meta, *children)


def _vargs_meta(f, _data, children, meta):
    return f(children, meta)  ##


def _vargs_tree(f, data, children, meta):
    return f(Tree(data, children, meta))


def v_args(inline=False, meta=False, tree=False, wrapper=None):
    # --
    if tree and (meta or inline):
        raise ValueError(
            "Visitor functions cannot combine 'tree' with 'meta' or 'inline'."
        )

    func = None
    if meta:
        if inline:
            func = _vargs_meta_inline
        else:
            func = _vargs_meta
    elif inline:
        func = _vargs_inline
    elif tree:
        func = _vargs_tree

    if wrapper is not None:
        if func is not None:
            raise ValueError(
                "Cannot use 'wrapper' along with 'tree', 'meta' or 'inline'."
            )
        func = wrapper

    def _visitor_args_dec(obj):
        return _apply_decorator(obj, _visitor_args_func_dec, visit_wrapper=func)

    return _visitor_args_dec


class Symbol(Serialize):
    __slots__ = ("name",)

    is_term = NotImplemented

    def __init__(self, name):
        self.name = name

    def __eq__(self, other):
        assert isinstance(other, Symbol), other
        return self.is_term == other.is_term and self.name == other.name

    def __ne__(self, other):
        return not (self == other)

    def __hash__(self):
        return hash(self.name)

    def __repr__(self):
        return "%s(%r)" % (type(self).__name__, self.name)

    fullrepr = property(__repr__)


class Terminal(Symbol):
    __serialize_fields__ = "name", "filter_out"

    is_term = True

    def __init__(self, name, filter_out=False):
        self.name = name
        self.filter_out = filter_out

    @property
    def fullrepr(self):
        return "%s(%r, %r)" % (type(self).__name__, self.name, self.filter_out)


class NonTerminal(Symbol):
    __serialize_fields__ = ("name",)

    is_term = False


class RuleOptions(Serialize):
    __serialize_fields__ = (
        "keep_all_tokens",
        "expand1",
        "priority",
        "template_source",
        "empty_indices",
    )

    def __init__(
        self,
        keep_all_tokens=False,
        expand1=False,
        priority=None,
        template_source=None,
        empty_indices=(),
    ):
        self.keep_all_tokens = keep_all_tokens
        self.expand1 = expand1
        self.priority = priority
        self.template_source = template_source
        self.empty_indices = empty_indices

    def __repr__(self):
        return "RuleOptions(%r, %r, %r, %r)" % (
            self.keep_all_tokens,
            self.expand1,
            self.priority,
            self.template_source,
        )


class Rule(Serialize):
    # --
    __slots__ = ("origin", "expansion", "alias", "options", "order", "_hash")

    __serialize_fields__ = "origin", "expansion", "order", "alias", "options"
    __serialize_namespace__ = Terminal, NonTerminal, RuleOptions

    def __init__(self, origin, expansion, order=0, alias=None, options=None):
        self.origin = origin
        self.expansion = expansion
        self.alias = alias
        self.order = order
        self.options = options or RuleOptions()
        self._hash = hash((self.origin, tuple(self.expansion)))

    def _deserialize(self):
        self._hash = hash((self.origin, tuple(self.expansion)))

    def __str__(self):
        return "<%s : %s>" % (
            self.origin.name,
            " ".join(x.name for x in self.expansion),
        )

    def __repr__(self):
        return "Rule(%r, %r, %r, %r)" % (
            self.origin,
            self.expansion,
            self.alias,
            self.options,
        )

    def __hash__(self):
        return self._hash

    def __eq__(self, other):
        if not isinstance(other, Rule):
            return False
        return self.origin == other.origin and self.expansion == other.expansion


from copy import copy


class Pattern(Serialize):
    raw = None
    type = None

    def __init__(self, value, flags=(), raw=None):
        self.value = value
        self.flags = frozenset(flags)
        self.raw = raw

    def __repr__(self):
        return repr(self.to_regexp())

    ##

    def __hash__(self):
        return hash((type(self), self.value, self.flags))

    def __eq__(self, other):
        return (
            type(self) == type(other)
            and self.value == other.value
            and self.flags == other.flags
        )

    def to_regexp(self):
        raise NotImplementedError()

    def min_width(self):
        raise NotImplementedError()

    def max_width(self):
        raise NotImplementedError()

    if Py36:
        ##

        def _get_flags(self, value):
            for f in self.flags:
                value = "(?%s:%s)" % (f, value)
            return value

    else:

        def _get_flags(self, value):
            for f in self.flags:
                value = ("(?%s)" % f) + value
            return value


class PatternStr(Pattern):
    __serialize_fields__ = "value", "flags"

    type = "str"

    def to_regexp(self):
        return self._get_flags(re.escape(self.value))

    @property
    def min_width(self):
        return len(self.value)

    max_width = min_width


class PatternRE(Pattern):
    __serialize_fields__ = "value", "flags", "_width"

    type = "re"

    def to_regexp(self):
        return self._get_flags(self.value)

    _width = None

    def _get_width(self):
        if self._width is None:
            self._width = get_regexp_width(self.to_regexp())
        return self._width

    @property
    def min_width(self):
        return self._get_width()[0]

    @property
    def max_width(self):
        return self._get_width()[1]


class TerminalDef(Serialize):
    __serialize_fields__ = "name", "pattern", "priority"
    __serialize_namespace__ = PatternStr, PatternRE

    def __init__(self, name, pattern, priority=1):
        assert isinstance(pattern, Pattern), pattern
        self.name = name
        self.pattern = pattern
        self.priority = priority

    def __repr__(self):
        return "%s(%r, %r)" % (type(self).__name__, self.name, self.pattern)

    def user_repr(self):
        if self.name.startswith("__"):  ##

            return self.pattern.raw or self.name
        else:
            return self.name


class Token(Str):
    # --
    __slots__ = (
        "type",
        "pos_in_stream",
        "value",
        "line",
        "column",
        "end_line",
        "end_column",
        "end_pos",
    )

    def __new__(
        cls,
        type_,
        value,
        pos_in_stream=None,
        line=None,
        column=None,
        end_line=None,
        end_column=None,
        end_pos=None,
    ):
        try:
            self = super(Token, cls).__new__(cls, value)
        except UnicodeDecodeError:
            value = value.decode("latin1")
            self = super(Token, cls).__new__(cls, value)

        self.type = type_
        self.pos_in_stream = pos_in_stream
        self.value = value
        self.line = line
        self.column = column
        self.end_line = end_line
        self.end_column = end_column
        self.end_pos = end_pos
        return self

    def update(self, type_=None, value=None):
        return Token.new_borrow_pos(
            type_ if type_ is not None else self.type,
            value if value is not None else self.value,
            self,
        )

    @classmethod
    def new_borrow_pos(cls, type_, value, borrow_t):
        return cls(
            type_,
            value,
            borrow_t.pos_in_stream,
            borrow_t.line,
            borrow_t.column,
            borrow_t.end_line,
            borrow_t.end_column,
            borrow_t.end_pos,
        )

    def __reduce__(self):
        return (
            self.__class__,
            (self.type, self.value, self.pos_in_stream, self.line, self.column),
        )

    def __repr__(self):
        return "Token(%r, %r)" % (self.type, self.value)

    def __deepcopy__(self, memo):
        return Token(self.type, self.value, self.pos_in_stream, self.line, self.column)

    def __eq__(self, other):
        if isinstance(other, Token) and self.type != other.type:
            return False

        return Str.__eq__(self, other)

    __hash__ = Str.__hash__


class LineCounter:
    __slots__ = "char_pos", "line", "column", "line_start_pos", "newline_char"

    def __init__(self, newline_char):
        self.newline_char = newline_char
        self.char_pos = 0
        self.line = 1
        self.column = 1
        self.line_start_pos = 0

    def __eq__(self, other):
        if not isinstance(other, LineCounter):
            return NotImplemented

        return (
            self.char_pos == other.char_pos and self.newline_char == other.newline_char
        )

    def feed(self, token, test_newline=True):
        # --
        if test_newline:
            newlines = token.count(self.newline_char)
            if newlines:
                self.line += newlines
                self.line_start_pos = (
                    self.char_pos + token.rindex(self.newline_char) + 1
                )

        self.char_pos += len(token)
        self.column = self.char_pos - self.line_start_pos + 1


class UnlessCallback:
    def __init__(self, mres):
        self.mres = mres

    def __call__(self, t):
        for mre, type_from_index in self.mres:
            m = mre.match(t.value)
            if m:
                t.type = type_from_index[m.lastindex]
                break
        return t


class CallChain:
    def __init__(self, callback1, callback2, cond):
        self.callback1 = callback1
        self.callback2 = callback2
        self.cond = cond

    def __call__(self, t):
        t2 = self.callback1(t)
        return self.callback2(t) if self.cond(t2) else t2


def _create_unless(terminals, g_regex_flags, re_, use_bytes):
    tokens_by_type = classify(terminals, lambda t: type(t.pattern))
    assert len(tokens_by_type) <= 2, tokens_by_type.keys()
    embedded_strs = set()
    callback = {}
    for retok in tokens_by_type.get(PatternRE, []):
        unless = []
        for strtok in tokens_by_type.get(PatternStr, []):
            if strtok.priority > retok.priority:
                continue
            s = strtok.pattern.value
            m = re_.match(retok.pattern.to_regexp(), s, g_regex_flags)
            if m and m.group(0) == s:
                unless.append(strtok)
                if strtok.pattern.flags <= retok.pattern.flags:
                    embedded_strs.add(strtok)
        if unless:
            callback[retok.name] = UnlessCallback(
                build_mres(
                    unless, g_regex_flags, re_, match_whole=True, use_bytes=use_bytes
                )
            )

    terminals = [t for t in terminals if t not in embedded_strs]
    return terminals, callback


def _build_mres(terminals, max_size, g_regex_flags, match_whole, re_, use_bytes):
    ##

    ##

    ##

    postfix = "$" if match_whole else ""
    mres = []
    while terminals:
        pattern = u"|".join(
            u"(?P<%s>%s)" % (t.name, t.pattern.to_regexp() + postfix)
            for t in terminals[:max_size]
        )
        if use_bytes:
            pattern = pattern.encode("latin-1")
        try:
            mre = re_.compile(pattern, g_regex_flags)
        except AssertionError:  ##

            return _build_mres(
                terminals, max_size // 2, g_regex_flags, match_whole, re_, use_bytes
            )

        mres.append((mre, {i: n for n, i in mre.groupindex.items()}))
        terminals = terminals[max_size:]
    return mres


def build_mres(terminals, g_regex_flags, re_, use_bytes, match_whole=False):
    return _build_mres(
        terminals, len(terminals), g_regex_flags, match_whole, re_, use_bytes
    )


def _regexp_has_newline(r):
    # --
    return (
        "\n" in r or "\\n" in r or "\\s" in r or "[^" in r or ("(?s" in r and "." in r)
    )


class Lexer(object):
    # --
    lex = NotImplemented

    def make_lexer_state(self, text):
        line_ctr = LineCounter(b"\n" if isinstance(text, bytes) else "\n")
        return LexerState(text, line_ctr)


class TraditionalLexer(Lexer):
    def __init__(self, conf):
        terminals = list(conf.terminals)
        assert all(isinstance(t, TerminalDef) for t in terminals), terminals

        self.re = conf.re_module

        if not conf.skip_validation:
            ##

            for t in terminals:
                try:
                    self.re.compile(t.pattern.to_regexp(), conf.g_regex_flags)
                except self.re.error:
                    raise LexError("Cannot compile token %s: %s" % (t.name, t.pattern))

                if t.pattern.min_width == 0:
                    raise LexError(
                        "Lexer does not allow zero-width terminals. (%s: %s)"
                        % (t.name, t.pattern)
                    )

            if not (set(conf.ignore) <= {t.name for t in terminals}):
                raise LexError(
                    "Ignore terminals are not defined: %s"
                    % (set(conf.ignore) - {t.name for t in terminals})
                )

        ##

        self.newline_types = frozenset(
            t.name for t in terminals if _regexp_has_newline(t.pattern.to_regexp())
        )
        self.ignore_types = frozenset(conf.ignore)

        terminals.sort(
            key=lambda x: (
                -x.priority,
                -x.pattern.max_width,
                -len(x.pattern.value),
                x.name,
            )
        )
        self.terminals = terminals
        self.user_callbacks = conf.callbacks
        self.g_regex_flags = conf.g_regex_flags
        self.use_bytes = conf.use_bytes
        self.terminals_by_name = conf.terminals_by_name

        self._mres = None

    def _build(self):
        terminals, self.callback = _create_unless(
            self.terminals, self.g_regex_flags, self.re, self.use_bytes
        )
        assert all(self.callback.values())

        for type_, f in self.user_callbacks.items():
            if type_ in self.callback:
                ##

                self.callback[type_] = CallChain(
                    self.callback[type_], f, lambda t: t.type == type_
                )
            else:
                self.callback[type_] = f

        self._mres = build_mres(terminals, self.g_regex_flags, self.re, self.use_bytes)

    @property
    def mres(self):
        if self._mres is None:
            self._build()
        return self._mres

    def match(self, text, pos):
        for mre, type_from_index in self.mres:
            m = mre.match(text, pos)
            if m:
                return m.group(0), type_from_index[m.lastindex]

    def lex(self, state, parser_state):
        with suppress(EOFError):
            while True:
                yield self.next_token(state, parser_state)

    def next_token(self, lex_state, parser_state=None):
        line_ctr = lex_state.line_ctr
        while line_ctr.char_pos < len(lex_state.text):
            res = self.match(lex_state.text, line_ctr.char_pos)
            if not res:
                allowed = {
                    v for m, tfi in self.mres for v in tfi.values()
                } - self.ignore_types
                if not allowed:
                    allowed = {"<END-OF-FILE>"}
                raise UnexpectedCharacters(
                    lex_state.text,
                    line_ctr.char_pos,
                    line_ctr.line,
                    line_ctr.column,
                    allowed=allowed,
                    token_history=lex_state.last_token and [lex_state.last_token],
                    state=parser_state,
                    terminals_by_name=self.terminals_by_name,
                )

            value, type_ = res

            if type_ not in self.ignore_types:
                t = Token(
                    type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column
                )
                line_ctr.feed(value, type_ in self.newline_types)
                t.end_line = line_ctr.line
                t.end_column = line_ctr.column
                t.end_pos = line_ctr.char_pos
                if t.type in self.callback:
                    t = self.callback[t.type](t)
                    if not isinstance(t, Token):
                        raise LexError(
                            "Callbacks must return a token (returned %r)" % t
                        )
                lex_state.last_token = t
                return t
            else:
                if type_ in self.callback:
                    t2 = Token(
                        type_, value, line_ctr.char_pos, line_ctr.line, line_ctr.column
                    )
                    self.callback[type_](t2)
                line_ctr.feed(value, type_ in self.newline_types)

        ##

        raise EOFError(self)


class LexerState(object):
    __slots__ = "text", "line_ctr", "last_token"

    def __init__(self, text, line_ctr, last_token=None):
        self.text = text
        self.line_ctr = line_ctr
        self.last_token = last_token

    def __eq__(self, other):
        if not isinstance(other, LexerState):
            return NotImplemented

        return (
            self.text is other.text
            and self.line_ctr == other.line_ctr
            and self.last_token == other.last_token
        )

    def __copy__(self):
        return type(self)(self.text, copy(self.line_ctr), self.last_token)


class ContextualLexer(Lexer):
    def __init__(self, conf, states, always_accept=()):
        terminals = list(conf.terminals)
        terminals_by_name = conf.terminals_by_name

        trad_conf = copy(conf)
        trad_conf.terminals = terminals

        lexer_by_tokens = {}
        self.lexers = {}
        for state, accepts in states.items():
            key = frozenset(accepts)
            try:
                lexer = lexer_by_tokens[key]
            except KeyError:
                accepts = set(accepts) | set(conf.ignore) | set(always_accept)
                lexer_conf = copy(trad_conf)
                lexer_conf.terminals = [
                    terminals_by_name[n] for n in accepts if n in terminals_by_name
                ]
                lexer = TraditionalLexer(lexer_conf)
                lexer_by_tokens[key] = lexer

            self.lexers[state] = lexer

        assert trad_conf.terminals is terminals
        self.root_lexer = TraditionalLexer(trad_conf)

    def make_lexer_state(self, text):
        return self.root_lexer.make_lexer_state(text)

    def lex(self, lexer_state, parser_state):
        try:
            while True:
                lexer = self.lexers[parser_state.position]
                yield lexer.next_token(lexer_state, parser_state)
        except EOFError:
            pass
        except UnexpectedCharacters as e:
            ##

            ##

            try:
                last_token = lexer_state.last_token  ##

                token = self.root_lexer.next_token(lexer_state, parser_state)
                raise UnexpectedToken(
                    token,
                    e.allowed,
                    state=parser_state,
                    token_history=[last_token],
                    terminals_by_name=self.root_lexer.terminals_by_name,
                )
            except UnexpectedCharacters:
                raise e  ##


class LexerThread(object):
    # --

    def __init__(self, lexer, text):
        self.lexer = lexer
        self.state = lexer.make_lexer_state(text)

    def lex(self, parser_state):
        return self.lexer.lex(self.state, parser_state)

    def __copy__(self):
        copied = object.__new__(LexerThread)
        copied.lexer = self.lexer
        copied.state = copy(self.state)
        return copied


class LexerConf(Serialize):
    __serialize_fields__ = (
        "terminals",
        "ignore",
        "g_regex_flags",
        "use_bytes",
        "lexer_type",
    )
    __serialize_namespace__ = (TerminalDef,)

    def __init__(
        self,
        terminals,
        re_module,
        ignore=(),
        postlex=None,
        callbacks=None,
        g_regex_flags=0,
        skip_validation=False,
        use_bytes=False,
    ):
        self.terminals = terminals
        self.terminals_by_name = {t.name: t for t in self.terminals}
        assert len(self.terminals) == len(self.terminals_by_name)
        self.ignore = ignore
        self.postlex = postlex
        self.callbacks = callbacks or {}
        self.g_regex_flags = g_regex_flags
        self.re_module = re_module
        self.skip_validation = skip_validation
        self.use_bytes = use_bytes
        self.lexer_type = None

    @property
    def tokens(self):
        warn(
            "LexerConf.tokens is deprecated. Use LexerConf.terminals instead",
            DeprecationWarning,
        )
        return self.terminals

    def _deserialize(self):
        self.terminals_by_name = {t.name: t for t in self.terminals}


class ParserConf(Serialize):
    __serialize_fields__ = "rules", "start", "parser_type"

    def __init__(self, rules, callbacks, start):
        assert isinstance(start, list)
        self.rules = rules
        self.callbacks = callbacks
        self.start = start

        self.parser_type = None


from functools import partial, wraps
from itertools import repeat, product


class ExpandSingleChild:
    def __init__(self, node_builder):
        self.node_builder = node_builder

    def __call__(self, children):
        if len(children) == 1:
            return children[0]
        else:
            return self.node_builder(children)


class PropagatePositions:
    def __init__(self, node_builder):
        self.node_builder = node_builder

    def __call__(self, children):
        res = self.node_builder(children)

        ##

        if isinstance(res, Tree):
            res_meta = res.meta
            for c in children:
                if isinstance(c, Tree):
                    child_meta = c.meta
                    if not child_meta.empty:
                        res_meta.line = child_meta.line
                        res_meta.column = child_meta.column
                        res_meta.start_pos = child_meta.start_pos
                        res_meta.empty = False
                        break
                elif isinstance(c, Token):
                    res_meta.line = c.line
                    res_meta.column = c.column
                    res_meta.start_pos = c.pos_in_stream
                    res_meta.empty = False
                    break

            for c in reversed(children):
                if isinstance(c, Tree):
                    child_meta = c.meta
                    if not child_meta.empty:
                        res_meta.end_line = child_meta.end_line
                        res_meta.end_column = child_meta.end_column
                        res_meta.end_pos = child_meta.end_pos
                        res_meta.empty = False
                        break
                elif isinstance(c, Token):
                    res_meta.end_line = c.end_line
                    res_meta.end_column = c.end_column
                    res_meta.end_pos = c.end_pos
                    res_meta.empty = False
                    break

        return res


class ChildFilter:
    def __init__(self, to_include, append_none, node_builder):
        self.node_builder = node_builder
        self.to_include = to_include
        self.append_none = append_none

    def __call__(self, children):
        filtered = []

        for i, to_expand, add_none in self.to_include:
            if add_none:
                filtered += [None] * add_none
            if to_expand:
                filtered += children[i].children
            else:
                filtered.append(children[i])

        if self.append_none:
            filtered += [None] * self.append_none

        return self.node_builder(filtered)


class ChildFilterLALR(ChildFilter):
    # --

    def __call__(self, children):
        filtered = []
        for i, to_expand, add_none in self.to_include:
            if add_none:
                filtered += [None] * add_none
            if to_expand:
                if filtered:
                    filtered += children[i].children
                else:  ##

                    filtered = children[i].children
            else:
                filtered.append(children[i])

        if self.append_none:
            filtered += [None] * self.append_none

        return self.node_builder(filtered)


class ChildFilterLALR_NoPlaceholders(ChildFilter):
    # --
    def __init__(self, to_include, node_builder):
        self.node_builder = node_builder
        self.to_include = to_include

    def __call__(self, children):
        filtered = []
        for i, to_expand in self.to_include:
            if to_expand:
                if filtered:
                    filtered += children[i].children
                else:  ##

                    filtered = children[i].children
            else:
                filtered.append(children[i])
        return self.node_builder(filtered)


def _should_expand(sym):
    return not sym.is_term and sym.name.startswith("_")


def maybe_create_child_filter(expansion, keep_all_tokens, ambiguous, _empty_indices):
    ##

    if _empty_indices:
        assert _empty_indices.count(False) == len(expansion)
        s = "".join(str(int(b)) for b in _empty_indices)
        empty_indices = [len(ones) for ones in s.split("0")]
        assert len(empty_indices) == len(expansion) + 1, (empty_indices, len(expansion))
    else:
        empty_indices = [0] * (len(expansion) + 1)

    to_include = []
    nones_to_add = 0
    for i, sym in enumerate(expansion):
        nones_to_add += empty_indices[i]
        if keep_all_tokens or not (sym.is_term and sym.filter_out):
            to_include.append((i, _should_expand(sym), nones_to_add))
            nones_to_add = 0

    nones_to_add += empty_indices[len(expansion)]

    if (
        _empty_indices
        or len(to_include) < len(expansion)
        or any(to_expand for i, to_expand, _ in to_include)
    ):
        if _empty_indices or ambiguous:
            return partial(
                ChildFilter if ambiguous else ChildFilterLALR, to_include, nones_to_add
            )
        else:
            ##

            return partial(
                ChildFilterLALR_NoPlaceholders, [(i, x) for i, x, _ in to_include]
            )


class AmbiguousExpander:
    # --
    def __init__(self, to_expand, tree_class, node_builder):
        self.node_builder = node_builder
        self.tree_class = tree_class
        self.to_expand = to_expand

    def __call__(self, children):
        def _is_ambig_tree(t):
            return hasattr(t, "data") and t.data == "_ambig"

        ##

        ##

        ##

        ##

        ambiguous = []
        for i, child in enumerate(children):
            if _is_ambig_tree(child):
                if i in self.to_expand:
                    ambiguous.append(i)

                to_expand = [
                    j
                    for j, grandchild in enumerate(child.children)
                    if _is_ambig_tree(grandchild)
                ]
                child.expand_kids_by_index(*to_expand)

        if not ambiguous:
            return self.node_builder(children)

        expand = [
            iter(child.children) if i in ambiguous else repeat(child)
            for i, child in enumerate(children)
        ]
        return self.tree_class(
            "_ambig", [self.node_builder(list(f[0])) for f in product(zip(*expand))]
        )


def maybe_create_ambiguous_expander(tree_class, expansion, keep_all_tokens):
    to_expand = [
        i
        for i, sym in enumerate(expansion)
        if keep_all_tokens
        or ((not (sym.is_term and sym.filter_out)) and _should_expand(sym))
    ]
    if to_expand:
        return partial(AmbiguousExpander, to_expand, tree_class)


class AmbiguousIntermediateExpander:
    # --

    def __init__(self, tree_class, node_builder):
        self.node_builder = node_builder
        self.tree_class = tree_class

    def __call__(self, children):
        def _is_iambig_tree(child):
            return hasattr(child, "data") and child.data == "_iambig"

        def _collapse_iambig(children):
            # --

            ##

            ##

            if children and _is_iambig_tree(children[0]):
                iambig_node = children[0]
                result = []
                for grandchild in iambig_node.children:
                    collapsed = _collapse_iambig(grandchild.children)
                    if collapsed:
                        for child in collapsed:
                            child.children += children[1:]
                        result += collapsed
                    else:
                        new_tree = self.tree_class(
                            "_inter", grandchild.children + children[1:]
                        )
                        result.append(new_tree)
                return result

        collapsed = _collapse_iambig(children)
        if collapsed:
            processed_nodes = [self.node_builder(c.children) for c in collapsed]
            return self.tree_class("_ambig", processed_nodes)

        return self.node_builder(children)


def ptb_inline_args(func):
    @wraps(func)
    def f(children):
        return func(*children)

    return f


def inplace_transformer(func):
    @wraps(func)
    def f(children):
        ##

        tree = Tree(func.__name__, children)
        return func(tree)

    return f


def apply_visit_wrapper(func, name, wrapper):
    if wrapper is _vargs_meta or wrapper is _vargs_meta_inline:
        raise NotImplementedError("Meta args not supported for internal transformer")

    @wraps(func)
    def f(children):
        return wrapper(func, name, children, None)

    return f


class ParseTreeBuilder:
    def __init__(
        self,
        rules,
        tree_class,
        propagate_positions=False,
        ambiguous=False,
        maybe_placeholders=False,
    ):
        self.tree_class = tree_class
        self.propagate_positions = propagate_positions
        self.ambiguous = ambiguous
        self.maybe_placeholders = maybe_placeholders

        self.rule_builders = list(self._init_builders(rules))

    def _init_builders(self, rules):
        for rule in rules:
            options = rule.options
            keep_all_tokens = options.keep_all_tokens
            expand_single_child = options.expand1

            wrapper_chain = list(
                filter(
                    None,
                    [
                        (expand_single_child and not rule.alias) and ExpandSingleChild,
                        maybe_create_child_filter(
                            rule.expansion,
                            keep_all_tokens,
                            self.ambiguous,
                            options.empty_indices if self.maybe_placeholders else None,
                        ),
                        self.propagate_positions and PropagatePositions,
                        self.ambiguous
                        and maybe_create_ambiguous_expander(
                            self.tree_class, rule.expansion, keep_all_tokens
                        ),
                        self.ambiguous
                        and partial(AmbiguousIntermediateExpander, self.tree_class),
                    ],
                )
            )

            yield rule, wrapper_chain

    def create_callback(self, transformer=None):
        callbacks = {}

        for rule, wrapper_chain in self.rule_builders:

            user_callback_name = (
                rule.alias or rule.options.template_source or rule.origin.name
            )
            try:
                f = getattr(transformer, user_callback_name)
                ##

                wrapper = getattr(f, "visit_wrapper", None)
                if wrapper is not None:
                    f = apply_visit_wrapper(f, user_callback_name, wrapper)
                else:
                    if isinstance(transformer, InlineTransformer):
                        f = ptb_inline_args(f)
                    elif isinstance(transformer, Transformer_InPlace):
                        f = inplace_transformer(f)
            except AttributeError:
                f = partial(self.tree_class, user_callback_name)

            for w in wrapper_chain:
                f = w(f)

            if rule in callbacks:
                raise GrammarError("Rule '%s' already exists" % (rule,))

            callbacks[rule] = f

        return callbacks


class LALR_Parser(Serialize):
    def __init__(self, parser_conf, debug=False):
        analysis = LALR_Analyzer(parser_conf, debug=debug)
        analysis.compute_lalr()
        callbacks = parser_conf.callbacks

        self._parse_table = analysis.parse_table
        self.parser_conf = parser_conf
        self.parser = _Parser(analysis.parse_table, callbacks, debug)

    @classmethod
    def deserialize(cls, data, memo, callbacks, debug=False):
        inst = cls.__new__(cls)
        inst._parse_table = IntParseTable.deserialize(data, memo)
        inst.parser = _Parser(inst._parse_table, callbacks, debug)
        return inst

    def serialize(self, memo):
        return self._parse_table.serialize(memo)

    def parse_interactive(self, lexer, start):
        return self.parser.parse(lexer, start, start_interactive=True)

    def parse(self, lexer, start, on_error=None):
        try:
            return self.parser.parse(lexer, start)
        except UnexpectedInput as e:
            if on_error is None:
                raise

            while True:
                if isinstance(e, UnexpectedCharacters):
                    s = e.interactive_parser.lexer_state.state
                    p = s.line_ctr.char_pos

                if not on_error(e):
                    raise e

                if isinstance(e, UnexpectedCharacters):
                    ##

                    if p == s.line_ctr.char_pos:
                        s.line_ctr.feed(s.text[p : p + 1])

                try:
                    return e.interactive_parser.resume_parse()
                except UnexpectedToken as e2:
                    if (
                        isinstance(e, UnexpectedToken)
                        and e.token.type == e2.token.type == "$END"
                        and e.interactive_parser == e2.interactive_parser
                    ):
                        ##

                        raise e2
                    e = e2
                except UnexpectedCharacters as e2:
                    e = e2


class ParseConf(object):
    __slots__ = (
        "parse_table",
        "callbacks",
        "start",
        "start_state",
        "end_state",
        "states",
    )

    def __init__(self, parse_table, callbacks, start):
        self.parse_table = parse_table

        self.start_state = self.parse_table.start_states[start]
        self.end_state = self.parse_table.end_states[start]
        self.states = self.parse_table.states

        self.callbacks = callbacks
        self.start = start


class ParserState(object):
    __slots__ = "parse_conf", "lexer", "state_stack", "value_stack"

    def __init__(self, parse_conf, lexer, state_stack=None, value_stack=None):
        self.parse_conf = parse_conf
        self.lexer = lexer
        self.state_stack = state_stack or [self.parse_conf.start_state]
        self.value_stack = value_stack or []

    @property
    def position(self):
        return self.state_stack[-1]

    ##

    def __eq__(self, other):
        if not isinstance(other, ParserState):
            return NotImplemented
        return (
            len(self.state_stack) == len(other.state_stack)
            and self.position == other.position
        )

    def __copy__(self):
        return type(self)(
            self.parse_conf,
            self.lexer,  ##
            copy(self.state_stack),
            deepcopy(self.value_stack),
        )

    def copy(self):
        return copy(self)

    def feed_token(self, token, is_end=False):
        state_stack = self.state_stack
        value_stack = self.value_stack
        states = self.parse_conf.states
        end_state = self.parse_conf.end_state
        callbacks = self.parse_conf.callbacks

        while True:
            state = state_stack[-1]
            try:
                action, arg = states[state][token.type]
            except KeyError:
                expected = {s for s in states[state].keys() if s.isupper()}
                raise UnexpectedToken(
                    token, expected, state=self, interactive_parser=None
                )

            assert arg != end_state

            if action is Shift:
                ##

                assert not is_end
                state_stack.append(arg)
                value_stack.append(
                    token
                    if token.type not in callbacks
                    else callbacks[token.type](token)
                )
                return
            else:
                ##

                rule = arg
                size = len(rule.expansion)
                if size:
                    s = value_stack[-size:]
                    del state_stack[-size:]
                    del value_stack[-size:]
                else:
                    s = []

                value = callbacks[rule](s)

                _action, new_state = states[state_stack[-1]][rule.origin.name]
                assert _action is Shift
                state_stack.append(new_state)
                value_stack.append(value)

                if is_end and state_stack[-1] == end_state:
                    return value_stack[-1]


class _Parser(object):
    def __init__(self, parse_table, callbacks, debug=False):
        self.parse_table = parse_table
        self.callbacks = callbacks
        self.debug = debug

    def parse(
        self, lexer, start, value_stack=None, state_stack=None, start_interactive=False
    ):
        parse_conf = ParseConf(self.parse_table, self.callbacks, start)
        parser_state = ParserState(parse_conf, lexer, state_stack, value_stack)
        if start_interactive:
            return InteractiveParser(self, parser_state, parser_state.lexer)
        return self.parse_from_state(parser_state)

    def parse_from_state(self, state):
        ##

        try:
            token = None
            for token in state.lexer.lex(state):
                state.feed_token(token)

            token = (
                Token.new_borrow_pos("$END", "", token)
                if token
                else Token("$END", "", 0, 1, 1)
            )
            return state.feed_token(token, True)
        except UnexpectedInput as e:
            try:
                e.interactive_parser = InteractiveParser(self, state, state.lexer)
            except NameError:
                pass
            raise e
        except Exception as e:
            if self.debug:
                print("")
                print("STATE STACK DUMP")
                print("----------------")
                for i, s in enumerate(state.state_stack):
                    print("%d)" % i, s)
                print("")

            raise


class Action:
    def __init__(self, name):
        self.name = name

    def __str__(self):
        return self.name

    def __repr__(self):
        return str(self)


Shift = Action("Shift")
Reduce = Action("Reduce")


class ParseTable:
    def __init__(self, states, start_states, end_states):
        self.states = states
        self.start_states = start_states
        self.end_states = end_states

    def serialize(self, memo):
        tokens = Enumerator()
        rules = Enumerator()

        states = {
            state: {
                tokens.get(token): (
                    (1, arg.serialize(memo)) if action is Reduce else (0, arg)
                )
                for token, (action, arg) in actions.items()
            }
            for state, actions in self.states.items()
        }

        return {
            "tokens": tokens.reversed(),
            "states": states,
            "start_states": self.start_states,
            "end_states": self.end_states,
        }

    @classmethod
    def deserialize(cls, data, memo):
        tokens = data["tokens"]
        states = {
            state: {
                tokens[token]: (
                    (Reduce, Rule.deserialize(arg, memo))
                    if action == 1
                    else (Shift, arg)
                )
                for token, (action, arg) in actions.items()
            }
            for state, actions in data["states"].items()
        }
        return cls(states, data["start_states"], data["end_states"])


class IntParseTable(ParseTable):
    @classmethod
    def from_ParseTable(cls, parse_table):
        enum = list(parse_table.states)
        state_to_idx = {s: i for i, s in enumerate(enum)}
        int_states = {}

        for s, la in parse_table.states.items():
            la = {
                k: (v[0], state_to_idx[v[1]]) if v[0] is Shift else v
                for k, v in la.items()
            }
            int_states[state_to_idx[s]] = la

        start_states = {
            start: state_to_idx[s] for start, s in parse_table.start_states.items()
        }
        end_states = {
            start: state_to_idx[s] for start, s in parse_table.end_states.items()
        }
        return cls(int_states, start_states, end_states)


def _wrap_lexer(lexer_class):
    future_interface = getattr(lexer_class, "__future_interface__", False)
    if future_interface:
        return lexer_class
    else:

        class CustomLexerWrapper(Lexer):
            def __init__(self, lexer_conf):
                self.lexer = lexer_class(lexer_conf)

            def lex(self, lexer_state, parser_state):
                return self.lexer.lex(lexer_state.text)

        return CustomLexerWrapper


class MakeParsingFrontend:
    def __init__(self, parser_type, lexer_type):
        self.parser_type = parser_type
        self.lexer_type = lexer_type

    def __call__(self, lexer_conf, parser_conf, options):
        assert isinstance(lexer_conf, LexerConf)
        assert isinstance(parser_conf, ParserConf)
        parser_conf.parser_type = self.parser_type
        lexer_conf.lexer_type = self.lexer_type
        return ParsingFrontend(lexer_conf, parser_conf, options)

    @classmethod
    def deserialize(cls, data, memo, lexer_conf, callbacks, options):
        parser_conf = ParserConf.deserialize(data["parser_conf"], memo)
        parser = LALR_Parser.deserialize(data["parser"], memo, callbacks, options.debug)
        parser_conf.callbacks = callbacks
        return ParsingFrontend(lexer_conf, parser_conf, options, parser=parser)


class ParsingFrontend(Serialize):
    __serialize_fields__ = "lexer_conf", "parser_conf", "parser", "options"

    def __init__(self, lexer_conf, parser_conf, options, parser=None):
        self.parser_conf = parser_conf
        self.lexer_conf = lexer_conf
        self.options = options

        ##

        if parser:  ##

            self.parser = parser
        else:
            create_parser = {
                "lalr": create_lalr_parser,
                "earley": create_earley_parser,
                "cyk": CYK_FrontEnd,
            }[parser_conf.parser_type]
            self.parser = create_parser(lexer_conf, parser_conf, options)

        ##

        lexer_type = lexer_conf.lexer_type
        self.skip_lexer = False
        if lexer_type in ("dynamic", "dynamic_complete"):
            assert lexer_conf.postlex is None
            self.skip_lexer = True
            return

        try:
            create_lexer = {
                "standard": create_traditional_lexer,
                "contextual": create_contextual_lexer,
            }[lexer_type]
        except KeyError:
            assert issubclass(lexer_type, Lexer), lexer_type
            self.lexer = _wrap_lexer(lexer_type)(lexer_conf)
        else:
            self.lexer = create_lexer(lexer_conf, self.parser, lexer_conf.postlex)

        if lexer_conf.postlex:
            self.lexer = PostLexConnector(self.lexer, lexer_conf.postlex)

    def _verify_start(self, start=None):
        if start is None:
            start = self.parser_conf.start
            if len(start) > 1:
                raise ConfigurationError(
                    "Lark initialized with more than 1 possible start rule. Must specify which start rule to parse",
                    start,
                )
            (start,) = start
        elif start not in self.parser_conf.start:
            raise ConfigurationError(
                "Unknown start rule %s. Must be one of %r"
                % (start, self.parser_conf.start)
            )
        return start

    def parse(self, text, start=None, on_error=None):
        start = self._verify_start(start)
        stream = text if self.skip_lexer else LexerThread(self.lexer, text)
        kw = {} if on_error is None else {"on_error": on_error}
        return self.parser.parse(stream, start, **kw)

    def parse_interactive(self, text=None, start=None):
        start = self._verify_start(start)
        if self.parser_conf.parser_type != "lalr":
            raise ConfigurationError(
                "parse_interactive() currently only works with parser='lalr' "
            )
        stream = text if self.skip_lexer else LexerThread(self.lexer, text)
        return self.parser.parse_interactive(stream, start)


def get_frontend(parser, lexer):
    assert_config(parser, ("lalr", "earley", "cyk"))
    if not isinstance(lexer, type):  ##

        expected = {
            "lalr": ("standard", "contextual"),
            "earley": ("standard", "dynamic", "dynamic_complete"),
            "cyk": ("standard",),
        }[parser]
        assert_config(
            lexer,
            expected,
            "Parser %r does not support lexer %%r, expected one of %%s" % parser,
        )

    return MakeParsingFrontend(parser, lexer)


def _get_lexer_callbacks(transformer, terminals):
    result = {}
    for terminal in terminals:
        callback = getattr(transformer, terminal.name, None)
        if callback is not None:
            result[terminal.name] = callback
    return result


class PostLexConnector:
    def __init__(self, lexer, postlexer):
        self.lexer = lexer
        self.postlexer = postlexer

    def make_lexer_state(self, text):
        return self.lexer.make_lexer_state(text)

    def lex(self, lexer_state, parser_state):
        i = self.lexer.lex(lexer_state, parser_state)
        return self.postlexer.process(i)


def create_traditional_lexer(lexer_conf, parser, postlex):
    return TraditionalLexer(lexer_conf)


def create_contextual_lexer(lexer_conf, parser, postlex):
    states = {idx: list(t.keys()) for idx, t in parser._parse_table.states.items()}
    always_accept = postlex.always_accept if postlex else ()
    return ContextualLexer(lexer_conf, states, always_accept=always_accept)


def create_lalr_parser(lexer_conf, parser_conf, options=None):
    debug = options.debug if options else False
    return LALR_Parser(parser_conf, debug=debug)


create_earley_parser = NotImplemented
CYK_FrontEnd = NotImplemented


class LarkOptions(Serialize):
    # --
    OPTIONS_DOC = """
    **===  General Options  ===**

    start
            The start symbol. Either a string, or a list of strings for multiple possible starts (Default: "start")
    debug
            Display debug information and extra warnings. Use only when debugging (default: False)
            When used with Earley, it generates a forest graph as "sppf.png", if 'dot' is installed.
    transformer
            Applies the transformer to every parse tree (equivalent to applying it after the parse, but faster)
    propagate_positions
            Propagates (line, column, end_line, end_column) attributes into all tree branches.
    maybe_placeholders
            When True, the ``[]`` operator returns ``None`` when not matched.

            When ``False``,  ``[]`` behaves like the ``?`` operator, and returns no value at all.
            (default= ``False``. Recommended to set to ``True``)
    cache
            Cache the results of the Lark grammar analysis, for x2 to x3 faster loading. LALR only for now.

            - When ``False``, does nothing (default)
            - When ``True``, caches to a temporary file in the local directory
            - When given a string, caches to the path pointed by the string
    regex
            When True, uses the ``regex`` module instead of the stdlib ``re``.
    g_regex_flags
            Flags that are applied to all terminals (both regex and strings)
    keep_all_tokens
            Prevent the tree builder from automagically removing "punctuation" tokens (default: False)
    tree_class
            Lark will produce trees comprised of instances of this class instead of the default ``lark.Tree``.

    **=== Algorithm Options ===**

    parser
            Decides which parser engine to use. Accepts "earley" or "lalr". (Default: "earley").
            (there is also a "cyk" option for legacy)
    lexer
            Decides whether or not to use a lexer stage

            - "auto" (default): Choose for me based on the parser
            - "standard": Use a standard lexer
            - "contextual": Stronger lexer (only works with parser="lalr")
            - "dynamic": Flexible and powerful (only with parser="earley")
            - "dynamic_complete": Same as dynamic, but tries *every* variation of tokenizing possible.
    ambiguity
            Decides how to handle ambiguity in the parse. Only relevant if parser="earley"

            - "resolve": The parser will automatically choose the simplest derivation
              (it chooses consistently: greedy for tokens, non-greedy for rules)
            - "explicit": The parser will return all derivations wrapped in "_ambig" tree nodes (i.e. a forest).
            - "forest": The parser will return the root of the shared packed parse forest.

    **=== Misc. / Domain Specific Options ===**

    postlex
            Lexer post-processing (Default: None) Only works with the standard and contextual lexers.
    priority
            How priorities should be evaluated - auto, none, normal, invert (Default: auto)
    lexer_callbacks
            Dictionary of callbacks for the lexer. May alter tokens during lexing. Use with caution.
    use_bytes
            Accept an input of type ``bytes`` instead of ``str`` (Python 3 only).
    edit_terminals
            A callback for editing the terminals before parse.
    import_paths
            A List of either paths or loader functions to specify from where grammars are imported
    source_path
            Override the source of from where the grammar was loaded. Useful for relative imports and unconventional grammar loading
    **=== End Options ===**
    """
    if __doc__:
        __doc__ += OPTIONS_DOC

    ##

    ##

    ##

    ##

    ##

    ##

    ##

    ##

    _defaults = {
        "debug": False,
        "keep_all_tokens": False,
        "tree_class": None,
        "cache": False,
        "postlex": None,
        "parser": "earley",
        "lexer": "auto",
        "transformer": None,
        "start": "start",
        "priority": "auto",
        "ambiguity": "auto",
        "regex": False,
        "propagate_positions": False,
        "lexer_callbacks": {},
        "maybe_placeholders": False,
        "edit_terminals": None,
        "g_regex_flags": 0,
        "use_bytes": False,
        "import_paths": [],
        "source_path": None,
    }

    def __init__(self, options_dict):
        o = dict(options_dict)

        options = {}
        for name, default in self._defaults.items():
            if name in o:
                value = o.pop(name)
                if isinstance(default, bool) and name not in ("cache", "use_bytes"):
                    value = bool(value)
            else:
                value = default

            options[name] = value

        if isinstance(options["start"], STRING_TYPE):
            options["start"] = [options["start"]]

        self.__dict__["options"] = options

        assert_config(self.parser, ("earley", "lalr", "cyk", None))

        if self.parser == "earley" and self.transformer:
            raise ConfigurationError(
                "Cannot specify an embedded transformer when using the Earley algorithm."
                "Please use your transformer on the resulting parse tree, or use a different algorithm (i.e. LALR)"
            )

        if o:
            raise ConfigurationError("Unknown options: %s" % o.keys())

    def __getattr__(self, name):
        try:
            return self.__dict__["options"][name]
        except KeyError as e:
            raise AttributeError(e)

    def __setattr__(self, name, value):
        assert_config(
            name, self.options.keys(), "%r isn't a valid option. Expected one of: %s"
        )
        self.options[name] = value

    def serialize(self, memo):
        return self.options

    @classmethod
    def deserialize(cls, data, memo):
        return cls(data)


##

##

_LOAD_ALLOWED_OPTIONS = {
    "postlex",
    "transformer",
    "lexer_callbacks",
    "use_bytes",
    "debug",
    "g_regex_flags",
    "regex",
    "propagate_positions",
    "tree_class",
}

_VALID_PRIORITY_OPTIONS = ("auto", "normal", "invert", None)
_VALID_AMBIGUITY_OPTIONS = ("auto", "resolve", "explicit", "forest")


class PostLex(ABC):
    @abstractmethod
    def process(self, stream):
        return stream

    always_accept = ()


class Lark(Serialize):
    # --
    def __init__(self, grammar, **options):
        self.options = LarkOptions(options)

        ##

        use_regex = self.options.regex
        if use_regex:
            if regex:
                re_module = regex
            else:
                raise ImportError(
                    "`regex` module must be installed if calling `Lark(regex=True)`."
                )
        else:
            re_module = re

        ##

        if self.options.source_path is None:
            try:
                self.source_path = grammar.name
            except AttributeError:
                self.source_path = "<string>"
        else:
            self.source_path = self.options.source_path

        ##

        try:
            read = grammar.read
        except AttributeError:
            pass
        else:
            grammar = read()

        cache_fn = None
        cache_md5 = None
        if isinstance(grammar, STRING_TYPE):
            self.source_grammar = grammar
            if self.options.use_bytes:
                if not isascii(grammar):
                    raise ConfigurationError(
                        "Grammar must be ascii only, when use_bytes=True"
                    )
                if sys.version_info[0] == 2 and self.options.use_bytes != "force":
                    raise ConfigurationError(
                        "`use_bytes=True` may have issues on python2."
                        "Use `use_bytes='force'` to use it at your own risk."
                    )

            if self.options.cache:
                if self.options.parser != "lalr":
                    raise ConfigurationError(
                        "cache only works with parser='lalr' for now"
                    )

                unhashable = (
                    "transformer",
                    "postlex",
                    "lexer_callbacks",
                    "edit_terminals",
                )
                options_str = "".join(
                    k + str(v) for k, v in options.items() if k not in unhashable
                )
                from . import __version__

                s = grammar + options_str + __version__ + str(sys.version_info[:2])
                cache_md5 = hashlib.md5(s.encode("utf8")).hexdigest()

                if isinstance(self.options.cache, STRING_TYPE):
                    cache_fn = self.options.cache
                else:
                    if self.options.cache is not True:
                        raise ConfigurationError("cache argument must be bool or str")
                    ##

                    cache_fn = tempfile.gettempdir() + "/.lark_cache_%s_%s_%s.tmp" % (
                        (cache_md5,) + sys.version_info[:2]
                    )

                if FS.exists(cache_fn):
                    logger.debug("Loading grammar from cache: %s", cache_fn)
                    ##

                    for name in set(options) - _LOAD_ALLOWED_OPTIONS:
                        del options[name]
                    with FS.open(cache_fn, "rb") as f:
                        old_options = self.options
                        try:
                            file_md5 = f.readline().rstrip(b"\n")
                            cached_used_files = pickle.load(f)
                            if file_md5 == cache_md5.encode(
                                "utf8"
                            ) and verify_used_files(cached_used_files):
                                cached_parser_data = pickle.load(f)
                                self._load(cached_parser_data, **options)
                                return
                        except Exception:  ##

                            logger.exception(
                                "Failed to load Lark from cache: %r. We will try to carry on."
                                % cache_fn
                            )

                            ##

                            ##

                            self.options = old_options

            ##

            self.grammar, used_files = load_grammar(
                grammar,
                self.source_path,
                self.options.import_paths,
                self.options.keep_all_tokens,
            )
        else:
            assert isinstance(grammar, Grammar)
            self.grammar = grammar

        if self.options.lexer == "auto":
            if self.options.parser == "lalr":
                self.options.lexer = "contextual"
            elif self.options.parser == "earley":
                if self.options.postlex is not None:
                    logger.info(
                        "postlex can't be used with the dynamic lexer, so we use standard instead. "
                        "Consider using lalr with contextual instead of earley"
                    )
                    self.options.lexer = "standard"
                else:
                    self.options.lexer = "dynamic"
            elif self.options.parser == "cyk":
                self.options.lexer = "standard"
            else:
                assert False, self.options.parser
        lexer = self.options.lexer
        if isinstance(lexer, type):
            assert issubclass(lexer, Lexer)  ##

        else:
            assert_config(
                lexer, ("standard", "contextual", "dynamic", "dynamic_complete")
            )
            if self.options.postlex is not None and "dynamic" in lexer:
                raise ConfigurationError(
                    "Can't use postlex with a dynamic lexer. Use standard or contextual instead"
                )

        if self.options.ambiguity == "auto":
            if self.options.parser == "earley":
                self.options.ambiguity = "resolve"
        else:
            assert_config(
                self.options.parser,
                ("earley", "cyk"),
                "%r doesn't support disambiguation. Use one of these parsers instead: %s",
            )

        if self.options.priority == "auto":
            self.options.priority = "normal"

        if self.options.priority not in _VALID_PRIORITY_OPTIONS:
            raise ConfigurationError(
                "invalid priority option: %r. Must be one of %r"
                % (self.options.priority, _VALID_PRIORITY_OPTIONS)
            )
        assert self.options.ambiguity not in (
            "resolve__antiscore_sum",
        ), 'resolve__antiscore_sum has been replaced with the option priority="invert"'
        if self.options.ambiguity not in _VALID_AMBIGUITY_OPTIONS:
            raise ConfigurationError(
                "invalid ambiguity option: %r. Must be one of %r"
                % (self.options.ambiguity, _VALID_AMBIGUITY_OPTIONS)
            )

        if self.options.postlex is not None:
            terminals_to_keep = set(self.options.postlex.always_accept)
        else:
            terminals_to_keep = set()

        ##

        self.terminals, self.rules, self.ignore_tokens = self.grammar.compile(
            self.options.start, terminals_to_keep
        )

        if self.options.edit_terminals:
            for t in self.terminals:
                self.options.edit_terminals(t)

        self._terminals_dict = {t.name: t for t in self.terminals}

        ##

        ##

        if self.options.priority == "invert":
            for rule in self.rules:
                if rule.options.priority is not None:
                    rule.options.priority = -rule.options.priority
        ##

        ##

        ##

        elif self.options.priority is None:
            for rule in self.rules:
                if rule.options.priority is not None:
                    rule.options.priority = None

        ##

        self.lexer_conf = LexerConf(
            self.terminals,
            re_module,
            self.ignore_tokens,
            self.options.postlex,
            self.options.lexer_callbacks,
            self.options.g_regex_flags,
            use_bytes=self.options.use_bytes,
        )

        if self.options.parser:
            self.parser = self._build_parser()
        elif lexer:
            self.lexer = self._build_lexer()

        if cache_fn:
            logger.debug("Saving grammar to cache: %s", cache_fn)
            with FS.open(cache_fn, "wb") as f:
                f.write(cache_md5.encode("utf8") + b"\n")
                pickle.dump(used_files, f)
                self.save(f)

    if __doc__:
        __doc__ += "\n\n" + LarkOptions.OPTIONS_DOC

    __serialize_fields__ = "parser", "rules", "options"

    def _build_lexer(self, dont_ignore=False):
        lexer_conf = self.lexer_conf
        if dont_ignore:
            from copy import copy

            lexer_conf = copy(lexer_conf)
            lexer_conf.ignore = ()
        return TraditionalLexer(lexer_conf)

    def _prepare_callbacks(self):
        self._callbacks = {}
        ##

        if self.options.ambiguity != "forest":
            self._parse_tree_builder = ParseTreeBuilder(
                self.rules,
                self.options.tree_class or Tree,
                self.options.propagate_positions,
                self.options.parser != "lalr" and self.options.ambiguity == "explicit",
                self.options.maybe_placeholders,
            )
            self._callbacks = self._parse_tree_builder.create_callback(
                self.options.transformer
            )
        self._callbacks.update(
            _get_lexer_callbacks(self.options.transformer, self.terminals)
        )

    def _build_parser(self):
        self._prepare_callbacks()
        parser_class = get_frontend(self.options.parser, self.options.lexer)
        parser_conf = ParserConf(self.rules, self._callbacks, self.options.start)
        return parser_class(self.lexer_conf, parser_conf, options=self.options)

    def save(self, f):
        # --
        data, m = self.memo_serialize([TerminalDef, Rule])
        pickle.dump({"data": data, "memo": m}, f, protocol=pickle.HIGHEST_PROTOCOL)

    @classmethod
    def load(cls, f):
        # --
        inst = cls.__new__(cls)
        return inst._load(f)

    def _deserialize_lexer_conf(self, data, memo, options):
        lexer_conf = LexerConf.deserialize(data["lexer_conf"], memo)
        lexer_conf.callbacks = options.lexer_callbacks or {}
        lexer_conf.re_module = regex if options.regex else re
        lexer_conf.use_bytes = options.use_bytes
        lexer_conf.g_regex_flags = options.g_regex_flags
        lexer_conf.skip_validation = True
        lexer_conf.postlex = options.postlex
        return lexer_conf

    def _load(self, f, **kwargs):
        if isinstance(f, dict):
            d = f
        else:
            d = pickle.load(f)
        memo = d["memo"]
        data = d["data"]

        assert memo
        memo = SerializeMemoizer.deserialize(
            memo, {"Rule": Rule, "TerminalDef": TerminalDef}, {}
        )
        options = dict(data["options"])
        if (set(kwargs) - _LOAD_ALLOWED_OPTIONS) & set(LarkOptions._defaults):
            raise ConfigurationError(
                "Some options are not allowed when loading a Parser: {}".format(
                    set(kwargs) - _LOAD_ALLOWED_OPTIONS
                )
            )
        options.update(kwargs)
        self.options = LarkOptions.deserialize(options, memo)
        self.rules = [Rule.deserialize(r, memo) for r in data["rules"]]
        self.source_path = "<deserialized>"
        parser_class = get_frontend(self.options.parser, self.options.lexer)
        self.lexer_conf = self._deserialize_lexer_conf(
            data["parser"], memo, self.options
        )
        self.terminals = self.lexer_conf.terminals
        self._prepare_callbacks()
        self._terminals_dict = {t.name: t for t in self.terminals}
        self.parser = parser_class.deserialize(
            data["parser"],
            memo,
            self.lexer_conf,
            self._callbacks,
            self.options,  ##
        )
        return self

    @classmethod
    def _load_from_dict(cls, data, memo, **kwargs):
        inst = cls.__new__(cls)
        return inst._load({"data": data, "memo": memo}, **kwargs)

    @classmethod
    def open(cls, grammar_filename, rel_to=None, **options):
        # --
        if rel_to:
            basepath = os.path.dirname(rel_to)
            grammar_filename = os.path.join(basepath, grammar_filename)
        with open(grammar_filename, encoding="utf8") as f:
            return cls(f, **options)

    @classmethod
    def open_from_package(cls, package, grammar_path, search_paths=("",), **options):
        # --
        package = FromPackageLoader(package, search_paths)
        full_path, text = package(None, grammar_path)
        options.setdefault("source_path", full_path)
        options.setdefault("import_paths", [])
        options["import_paths"].append(package)
        return cls(text, **options)

    def __repr__(self):
        return "Lark(open(%r), parser=%r, lexer=%r, ...)" % (
            self.source_path,
            self.options.parser,
            self.options.lexer,
        )

    def lex(self, text, dont_ignore=False):
        # --
        if not hasattr(self, "lexer") or dont_ignore:
            lexer = self._build_lexer(dont_ignore)
        else:
            lexer = self.lexer
        lexer_thread = LexerThread(lexer, text)
        stream = lexer_thread.lex(None)
        if self.options.postlex:
            return self.options.postlex.process(stream)
        return stream

    def get_terminal(self, name):
        # --
        return self._terminals_dict[name]

    def parse_interactive(self, text=None, start=None):
        return self.parser.parse_interactive(text, start=start)

    def parse(self, text, start=None, on_error=None):
        # --
        return self.parser.parse(text, start=start, on_error=on_error)

    @property
    def source(self):
        warn(
            "Lark.source attribute has been renamed to Lark.source_path",
            DeprecationWarning,
        )
        return self.source_path

    @source.setter
    def source(self, value):
        self.source_path = value

    @property
    def grammar_source(self):
        warn(
            "Lark.grammar_source attribute has been renamed to Lark.source_grammar",
            DeprecationWarning,
        )
        return self.source_grammar

    @grammar_source.setter
    def grammar_source(self, value):
        self.source_grammar = value


class DedentError(LarkError):
    pass


class Indenter(PostLex):
    def __init__(self):
        self.paren_level = None
        self.indent_level = None
        assert self.tab_len > 0

    def handle_NL(self, token):
        if self.paren_level > 0:
            return

        yield token

        indent_str = token.rsplit("\n", 1)[1]  ##

        indent = indent_str.count(" ") + indent_str.count("\t") * self.tab_len

        if indent > self.indent_level[-1]:
            self.indent_level.append(indent)
            yield Token.new_borrow_pos(self.INDENT_type, indent_str, token)
        else:
            while indent < self.indent_level[-1]:
                self.indent_level.pop()
                yield Token.new_borrow_pos(self.DEDENT_type, indent_str, token)

            if indent != self.indent_level[-1]:
                raise DedentError(
                    "Unexpected dedent to column %s. Expected dedent to %s"
                    % (indent, self.indent_level[-1])
                )

    def _process(self, stream):
        for token in stream:
            if token.type == self.NL_type:
                for t in self.handle_NL(token):
                    yield t
            else:
                yield token

            if token.type in self.OPEN_PAREN_types:
                self.paren_level += 1
            elif token.type in self.CLOSE_PAREN_types:
                self.paren_level -= 1
                assert self.paren_level >= 0

        while len(self.indent_level) > 1:
            self.indent_level.pop()
            yield Token(self.DEDENT_type, "")

        assert self.indent_level == [0], self.indent_level

    def process(self, stream):
        self.paren_level = 0
        self.indent_level = [0]
        return self._process(stream)

    ##

    @property
    def always_accept(self):
        return (self.NL_type,)


import pickle, zlib, base64

DATA = b"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"
DATA = pickle.loads(zlib.decompress(base64.b64decode(DATA)))
MEMO = b"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"
MEMO = pickle.loads(zlib.decompress(base64.b64decode(MEMO)))
Shift = 0
Reduce = 1


def Lark_StandAlone(**kwargs):
    return Lark._load_from_dict(DATA, MEMO, **kwargs)
